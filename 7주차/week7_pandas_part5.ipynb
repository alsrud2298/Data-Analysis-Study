{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 누락 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터분석의 정확도 -> 분석 데이터의 품질에 의해 좌우됨.\n",
    "- 누락 데이터, 중복 데이터 등 오류 수정하고 분석 목적에 맞게 변형하는 과정 필요\n",
    "- 일반적으로 유효한 데이터 값이 존재하지 않는 누락 데이터 -> NaN으로 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누락 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() \n",
    "# non-null값 개수 보여줌\n",
    "# RangeIndex : 각 열에 존재하는 데이터 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN    688\n",
       "C       59\n",
       "B       47\n",
       "D       33\n",
       "E       32\n",
       "A       15\n",
       "F       13\n",
       "G        4\n",
       "Name: deck, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_deck = df['deck'].value_counts(dropna=False)\n",
    "# dropna = True : Nan값 제외 유효한 데이터 개수만 출력\n",
    "nan_deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n",
      "\n",
      "\n",
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n"
     ]
    }
   ],
   "source": [
    "# isnull() : 누락데이터면 True, 유효한 데이터면 False 반환\n",
    "print(df.head().isnull())\n",
    "print(\"\\n\")\n",
    "# notnull() : 유효한 데이터면 True, 누락 데이터면 False 반환\n",
    "print(df.head().notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터 개수 구하기\n",
    "print(df.head().isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived : 0\n",
      "pclass : 0\n",
      "sex : 0\n",
      "age : 177\n",
      "sibsp : 0\n",
      "parch : 0\n",
      "fare : 0\n",
      "embarked : 2\n",
      "class : 0\n",
      "who : 0\n",
      "adult_male : 0\n",
      "deck : 688\n",
      "embark_town : 2\n",
      "alive : 0\n",
      "alone : 0\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터 제거\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "missing_df = df.isnull()\n",
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts()\n",
    "    try:\n",
    "        print(col, ':', missing_count[True])\n",
    "    except:\n",
    "        print(col, ':', 0)\n",
    "# 'deck'열의 누락 데이터 비율이 매우 높으므로 누락 데이터를 삭제하여\n",
    "# 분석에서 제외하는 것이 의미 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
       "       'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN값이 500개 이상인 열을 모두 삭제\n",
    "df_thresh = df.dropna(axis=1, thresh=500)\n",
    "df_thresh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 891명 중 177명의 나이 데이터 없음 \n",
    "# 나이가 중요한 변수인 경우, 나이 데이터가 없는 승객의 레코드 제거하는 것이 좋음.\n",
    "# how = 'any' : NaN값이 하나라도 존재하면 삭제\n",
    "# how = 'all' : 모든 데이터가 NaN값일 경우에만 삭제\n",
    "df_age = df.dropna(subset=['age'], how='any', axis=0)\n",
    "len(df_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누락 데이터 치환\n",
    "- 데이터 일부가 누락되었더라도 나머지 데이터를 최대한 살려서 활용하는 것이 좋은 경우가 많음.\n",
    "- 데이터의 분포와 특성을 잘 나타낼 수 있는 평균값, 최빈값 등으로 누락 데이터 치환\n",
    "- fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n",
      "0    22.000000\n",
      "1    38.000000\n",
      "2    26.000000\n",
      "3    35.000000\n",
      "4    35.000000\n",
      "5    29.699118\n",
      "6    54.000000\n",
      "7     2.000000\n",
      "8    27.000000\n",
      "9    14.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['age'].head(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "# age 열의 NaN값 다른 나이 데이터의 평균으로 대체\n",
    "mean_age = df['age'].mean(axis=0)\n",
    "df['age'].fillna(mean_age, inplace = True)\n",
    "\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "Southampton\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# embark_town 열의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print(\"\\n\")\n",
    "\n",
    "# 누락값 -> 최빈값으로 대체\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "print(most_freq)\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(most_freq, inplace = True)\n",
    "\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 누락 데이터가 NaN으로 표시되지 않은 경우\n",
    "    - replace() 메소드 활용하여 numpy에서 지원하는 np.nan으로 변경\n",
    "    - df.replace('?', np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829     Queenstown\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "# 데이터셋 특성 상 서로 이웃하는 데이터끼리 유사성 가질 가능성 높음\n",
    "print(df['embark_town'][825:830])\n",
    "print(\"\\n\")\n",
    "\n",
    "# NaN값 바로 앞의 값으로 변경\n",
    "df['embark_town'].fillna(method='ffill', inplace=True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중복 데이터 확인\n",
    "- duplicated() 메소드 이용\n",
    "- 중복되는 행인 경우 True, 아니면 False 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'c1':['a','a','b','a','b'],\n",
    "                  'c2':[1,1,1,2,2],\n",
    "                  'c3':[1,1,2,2,2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 중복값 찾기\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "Name: c2, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임의 특정 열 데이터에서 중복값 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "col_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중복 데이터 제거\n",
    "- drop_duplicates()\n",
    "    - 중복되는 행 제거 후 고유한 관측값 가진 행만 남김\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  c1  c2  c3\n",
       "0  a   1   1\n",
       "2  b   1   2\n",
       "3  a   2   2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 여부 판별 시 subset 옵션에 해당하는 열 기준으로 판단\n",
    "df3 = df.drop_duplicates(subset=['c2','c3'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. 단위 환산\n",
    "- 전체 데이터 일관성 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name       kpl  \n",
      "0       1  chevrolet chevelle malibu  7.652571  \n",
      "1       1          buick skylark 320  6.377143  \n",
      "2       1         plymouth satellite  7.652571  \n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name   kpl  \n",
      "0       1  chevrolet chevelle malibu  7.65  \n",
      "1       1          buick skylark 320  6.38  \n",
      "2       1         plymouth satellite  7.65  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/auto-mpg.csv', header = None)\n",
    "\n",
    "df.columns = ['mpg','cylinders', 'displacement', 'horsepower','weight',\n",
    "             'acceleration', 'model year', 'origin', 'name']\n",
    "print(df.head(3))\n",
    "print(\"\\n\")\n",
    "\n",
    "# mpg(mile per gallon) -> kpl(kilometer per liter) 변환\n",
    "mpg_to_kpl = 1.60934/3.78541\n",
    "\n",
    "# kpl 열 추가\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "print(df.head(3))\n",
    "print('\\n')\n",
    "\n",
    "# 소수점 둘째자리에서 반올림\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. 자료형 변환\n",
    "- info() 함수로 각 열의 자료형 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower       object\n",
       "weight          float64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "name             object\n",
       "kpl             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# horsepower -> 숫자형으로 변환\n",
    "\n",
    "# 고유값 확인\n",
    "df['horsepower'].unique()\n",
    "\n",
    "# 문자열 ? -> NaN 값으로 변환\n",
    "import numpy as np\n",
    "df['horsepower'].replace('?', np.nan, inplace = True)\n",
    "# 누락 데이터 삭제\n",
    "df.dropna(subset=['horsepower'], axis = 0, inplace = True)\n",
    "# 실수형으로 변환\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "# 자료형 확인\n",
    "df['horsepower'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n",
      "['USA' 'JPN' 'EU']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# origin열 정수형 데이터 -> 실제 국가 이름으로 변환\n",
    "print(df['origin'].unique())\n",
    "\n",
    "df['origin'].replace({1:'USA',2:'EU',3:'JPN'}, inplace = True)\n",
    "\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# 유한개의 고유값이 반복적으로 나타나는 경우 -> 범주형으로 표현\n",
    "# 문자열 -> 범주형\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "print(df['origin'].dtypes)\n",
    "# 범주형 -> 문자열\n",
    "df['origin'] = df['origin'].astype('str')\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14     70\n",
      "127    74\n",
      "57     72\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n",
      "230    77\n",
      "61     72\n",
      "60     72\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "# model year 열의 정수형을 범주형으로 변환\n",
    "print(df['model year'].sample(3)) # 무작위 3개 출력\n",
    "df['model year'] = df['model year'].astype('category')\n",
    "print(df['model year'].sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 범주형 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. 구간 분할\n",
    "- 연속 데이터를 일정한 구간(bin)으로 나눠 분석하는 것이 효율적인 경우\n",
    "- 구간 분할(binning) : 연속 변수 일정 구간으로 나누고 각 구간 범주형 이산 변수로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.         107.33333333 168.66666667 230.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horsepower</th>\n",
       "      <th>hp_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>198.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>215.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>225.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>190.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>170.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>160.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150.0</td>\n",
       "      <td>보통출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>225.0</td>\n",
       "      <td>고출력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>95.0</td>\n",
       "      <td>저출력</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    horsepower hp_bin\n",
       "0        130.0   보통출력\n",
       "1        165.0   보통출력\n",
       "2        150.0   보통출력\n",
       "3        150.0   보통출력\n",
       "4        140.0   보통출력\n",
       "5        198.0    고출력\n",
       "6        220.0    고출력\n",
       "7        215.0    고출력\n",
       "8        225.0    고출력\n",
       "9        190.0    고출력\n",
       "10       170.0    고출력\n",
       "11       160.0   보통출력\n",
       "12       150.0   보통출력\n",
       "13       225.0    고출력\n",
       "14        95.0    저출력"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, bin_dividers = np.histogram(df['horsepower'], bins = 3)\n",
    "print(bin_dividers)\n",
    "\n",
    "bin_names =['저출력','보통출력','고출력']\n",
    "\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'], # 데이터 배열\n",
    "                     bins = bin_dividers, # 경계값 리스트\n",
    "                     labels= bin_names, # bin 이름\n",
    "                      include_lowest = True) # 첫 경계값 포함\n",
    "df[['horsepower','hp_bin']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2. 더미 변수\n",
    "- 범주형 데이터를 회귀분석 등 머신러닝 알고리즘에 바로 사용할 수 없는 경우 -> 컴퓨터가 인식 가능한 값으로 변환 필요\n",
    "- 더미변수 : 0 또는 1로 표현 / 어떤 특성의 존재 여부 표시\n",
    "- 원핫벡터로 변환 -> 원핫인코딩\n",
    "- get_dummies() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    저출력  보통출력  고출력\n",
      "0     0     1    0\n",
      "1     0     1    0\n",
      "2     0     1    0\n",
      "3     0     1    0\n",
      "4     0     1    0\n",
      "5     0     0    1\n",
      "6     0     0    1\n",
      "7     0     0    1\n",
      "8     0     0    1\n",
      "9     0     0    1\n",
      "10    0     0    1\n",
      "11    0     1    0\n",
      "12    0     1    0\n",
      "13    0     0    1\n",
      "14    1     0    0\n"
     ]
    }
   ],
   "source": [
    "# 판다스 get_dummies 활용\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(horsepower_dummies.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]]\n",
      "<class 'numpy.ndarray'>\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 0)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# sklearn 라이브러리 활용\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 전처리를 위한 encoder 객체 만들기\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "# label encoder로 문자열 범주 -> 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "print(onehot_labeled)\n",
    "print(type(onehot_labeled))\n",
    "\n",
    "# 2차원 행렬로 변환\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled),1)\n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))\n",
    "\n",
    "# 최소행렬로 변환\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 정규화\n",
    "- 각 숫자데이터의 상대적 크기 차이로 인해 머신러닝 분석 결과 달라질 수 있음.\n",
    "- 상대적으로 큰 값을 갖는 변수의 영향이 더 큼\n",
    "- 정규화 : 각 변수에 속하는 데이터값을 동일 크기 기준으로 나눈 비율로 나타내는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    392.000000\n",
      "mean       0.454215\n",
      "std        0.167353\n",
      "min        0.200000\n",
      "25%        0.326087\n",
      "50%        0.406522\n",
      "75%        0.547826\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "0    0.565217\n",
      "1    0.717391\n",
      "2    0.652174\n",
      "3    0.652174\n",
      "4    0.608696\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "count    392.000000\n",
      "mean       0.454215\n",
      "std        0.167353\n",
      "min        0.200000\n",
      "25%        0.326087\n",
      "50%        0.406522\n",
      "75%        0.547826\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 최대값으로 나누기\n",
    "print(df.horsepower.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "df.horsepower = df.horsepower/abs(df.horsepower.max())\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print(\"\\n\")\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.456522\n",
      "1    0.646739\n",
      "2    0.565217\n",
      "3    0.565217\n",
      "4    0.510870\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "count    392.000000\n",
      "mean       0.317768\n",
      "std        0.209191\n",
      "min        0.000000\n",
      "25%        0.157609\n",
      "50%        0.258152\n",
      "75%        0.434783\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 최대값, 최소값 뺀 값으로 나누기\n",
    "# 분자 : 각 열 데이터 - 최소값\n",
    "# 분모 : 최대값 - 최소값\n",
    "\n",
    "min_x = df.horsepower - df.horsepower.min()\n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horsepower = min_x/min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print(\"\\n\")\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 시계열 데이터\n",
    "- Timestamp : 특정 시점 기록\n",
    "- Period : 두 시점 사이 일정 기간 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1. 다른 자료형을 시계열 객체로 변환\n",
    "- 판다스 to_datetime()\n",
    "    - 다른 자료형 -> 판다스 Timestamp로 변환\n",
    "    - datetime64 자료형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume\n",
      "0  2018-07-02  10100  10850  10900  10000  137977\n",
      "1  2018-06-29  10700  10550  10900   9990  170253\n",
      "2  2018-06-28  10400  10900  10950  10150  155769\n",
      "3  2018-06-27  10900  10800  11050  10500  133548\n",
      "4  2018-06-26  10800  10900  11000  10700   63039\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    20 non-null     object\n",
      " 1   Close   20 non-null     int64 \n",
      " 2   Start   20 non-null     int64 \n",
      " 3   High    20 non-null     int64 \n",
      " 4   Low     20 non-null     int64 \n",
      " 5   Volume  20 non-null     int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/stock-data.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      20 non-null     object        \n",
      " 1   Close     20 non-null     int64         \n",
      " 2   Start     20 non-null     int64         \n",
      " 3   High      20 non-null     int64         \n",
      " 4   Low       20 non-null     int64         \n",
      " 5   Volume    20 non-null     int64         \n",
      " 6   new_Date  20 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "# 'Date'열의 날짜데이터 -> datetime64 자료형으로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(df.info())\n",
    "print(\"\\n\")\n",
    "print(type(df['new_Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close  Start   High    Low  Volume\n",
      "new_Date                                      \n",
      "2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2018-07-02 to 2018-06-01\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Close   20 non-null     int64\n",
      " 1   Start   20 non-null     int64\n",
      " 2   High    20 non-null     int64\n",
      " 3   Low     20 non-null     int64\n",
      " 4   Volume  20 non-null     int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 960.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 시계열 값으로 변환된 열 새로운 행 인덱스로 지정\n",
    "# DatetimeIndex로 저장 -> 시간 순서에 맞춰 인덱싱/슬라이싱 편리\n",
    "df.set_index('new_Date', inplace= True)\n",
    "df.drop('Date', axis=1, inplace = True)\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "\n",
      "PeriodIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='period[D]', freq='D')\n",
      "PeriodIndex(['2019-01', '2020-03', '2021-06'], dtype='period[M]', freq='M')\n",
      "PeriodIndex(['2019', '2020', '2021'], dtype='period[A-DEC]', freq='A-DEC')\n"
     ]
    }
   ],
   "source": [
    "# Timestamp -> Period로 변환\n",
    "dates = ['2019-01-01', '2020-03-01', '2021-06-01']\n",
    "\n",
    "ts_dates = pd.to_datetime(dates)\n",
    "print(ts_dates)\n",
    "print(\"\\n\")\n",
    "\n",
    "pr_day = ts_dates.to_period(freq='D') # 1일\n",
    "print(pr_day)\n",
    "pr_month = ts_dates.to_period(freq='M') # 1개월\n",
    "print(pr_month)\n",
    "pr_year = ts_dates.to_period(freq='A') # 1년(12월기준)\n",
    "print(pr_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2. 시계열 데이터 만들기\n",
    "- date_range() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01 00:00:00+09:00', '2019-02-01 00:00:00+09:00',\n",
      "               '2019-03-01 00:00:00+09:00', '2019-04-01 00:00:00+09:00',\n",
      "               '2019-05-01 00:00:00+09:00', '2019-06-01 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "# 월 간격, 월 시작일 기준\n",
    "ts_ms = pd.date_range(start='2019-01-01', # 시작\n",
    "                     end = None, # 끝\n",
    "                     periods = 6, # 생성할 Timestamp 개수\n",
    "                     freq='MS', # 시간 간격(MS: 월 시작일)\n",
    "                     tz='Asia/Seoul') # 시간대\n",
    "print(ts_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-02-28 00:00:00+09:00',\n",
      "               '2019-03-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-05-31 00:00:00+09:00', '2019-06-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='M')\n",
      "\n",
      "\n",
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-07-31 00:00:00+09:00', '2019-10-31 00:00:00+09:00',\n",
      "               '2020-01-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='3M')\n"
     ]
    }
   ],
   "source": [
    "# 월 간격, 월 마지막 날 기준\n",
    "ts_me = pd.date_range(start='2019-01-01', # 시작\n",
    "                     periods = 6, # 생성할 Timestamp 개수\n",
    "                     freq='M', # 시간 간격(MS: 월 시작일)\n",
    "                     tz='Asia/Seoul') # 시간대\n",
    "print(ts_me)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 분기(3개월) 간격, 월 마지막 날 기준\n",
    "ts_3m = pd.date_range(start='2019-01-01', # 시작\n",
    "                     periods = 6, # 생성할 Timestamp 개수\n",
    "                     freq='3M', # 시간 간격(MS: 월 시작일)\n",
    "                     tz='Asia/Seoul') # 시간대\n",
    "print(ts_3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2019-02', '2019-03'], dtype='period[M]', freq='M')\n"
     ]
    }
   ],
   "source": [
    "# Period 배열 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01',\n",
    "                      end=None,\n",
    "                      periods=3,\n",
    "                      freq='M')\n",
    "print(pr_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01-01 00:00', '2019-01-01 01:00', '2019-01-01 02:00'], dtype='period[H]', freq='H')\n",
      "\n",
      "\n",
      "PeriodIndex(['2019-01-01 00:00', '2019-01-01 02:00', '2019-01-01 04:00'], dtype='period[2H]', freq='2H')\n"
     ]
    }
   ],
   "source": [
    "# Period 배열 - 1시간 길이\n",
    "pr_h = pd.period_range(start='2019-01-01',\n",
    "                      end=None,\n",
    "                      periods=3,\n",
    "                      freq='H')\n",
    "print(pr_h)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Period 배열 - 2시간 길이\n",
    "pr_2h = pd.period_range(start='2019-01-01',\n",
    "                      end=None,\n",
    "                      periods=3,\n",
    "                      freq='2H')\n",
    "print(pr_2h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-3. 시계열 데이터 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "\n",
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  Day\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7    2\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   26\n"
     ]
    }
   ],
   "source": [
    "# 날짜 데이터 분리\n",
    "\n",
    "df = pd.read_csv('./data/stock-data.csv')\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "df[\"Year\"] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  \\\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7   \n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   \n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   \n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   \n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   \n",
      "\n",
      "   Day Date_yr   Date_m  \n",
      "0    2    2018  2018-07  \n",
      "1   29    2018  2018-06  \n",
      "2   28    2018  2018-06  \n",
      "3   27    2018  2018-06  \n",
      "4   26    2018  2018-06  \n"
     ]
    }
   ],
   "source": [
    "# Timestamp -> Period로 변환\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date  Close  Start   High    Low  Volume   new_Date  Year  \\\n",
      "Date_m                                                                     \n",
      "2018-07  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018   \n",
      "2018-06  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018   \n",
      "2018-06  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018   \n",
      "2018-06  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018   \n",
      "2018-06  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018   \n",
      "\n",
      "         Month  Day Date_yr  \n",
      "Date_m                       \n",
      "2018-07      7    2    2018  \n",
      "2018-06      6   29    2018  \n",
      "2018-06      6   28    2018  \n",
      "2018-06      6   27    2018  \n",
      "2018-06      6   26    2018  \n"
     ]
    }
   ],
   "source": [
    "# 추출한 날짜 정보 행 인덱스로 지정\n",
    "df.set_index('Date_m', inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "DatetimeIndex(['2018-07-02', '2018-06-29', '2018-06-28', '2018-06-27',\n",
      "               '2018-06-26', '2018-06-25', '2018-06-22', '2018-06-21',\n",
      "               '2018-06-20', '2018-06-19', '2018-06-18', '2018-06-15',\n",
      "               '2018-06-14', '2018-06-12', '2018-06-11', '2018-06-08',\n",
      "               '2018-06-07', '2018-06-05', '2018-06-04', '2018-06-01'],\n",
      "              dtype='datetime64[ns]', name='new_Date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스 활용\n",
    "# Period 구성 열 행 인덱스 지정 -> PeriodIndex\n",
    "\n",
    "df = pd.read_csv('./data/stock-data.csv')\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('new_Date', inplace=True)\n",
    "print(df.head())\n",
    "print(\"\\n\")\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "\n",
      "\n",
      "            Start   High\n",
      "new_Date                \n",
      "2018-07-02  10850  10900\n",
      "\n",
      "\n",
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "\n",
      "\n",
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-06-25  2018-06-25  11150  11400  11450  11000   55519\n",
      "2018-06-22  2018-06-22  11300  11250  11450  10750  134805\n",
      "2018-06-21  2018-06-21  11200  11350  11750  11200  133002\n",
      "2018-06-20  2018-06-20  11550  11200  11600  10900  308596\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스로 인덱싱/슬라이싱\n",
    "df_y = df.loc['2018']\n",
    "print(df_y.head())\n",
    "print(\"\\n\")\n",
    "df_ym = df.loc['2018-07']\n",
    "print(df_ym)\n",
    "print(\"\\n\")\n",
    "df_ym_cols= df.loc['2018-07','Start':'High']\n",
    "print(df_ym_cols)\n",
    "print(\"\\n\")\n",
    "df_ymd = df.loc['2018-07-02']\n",
    "print(df_ymd)\n",
    "print(\"\\n\")\n",
    "df_ymd_range = df['2018-06-25':'2018-06-20']\n",
    "print(df_ymd_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "time_delta                                                \n",
      "180 days    2018-06-28  10400  10900  10950  10150  155769\n",
      "181 days    2018-06-27  10900  10800  11050  10500  133548\n",
      "182 days    2018-06-26  10800  10900  11000  10700   63039\n",
      "183 days    2018-06-25  11150  11400  11450  11000   55519\n",
      "186 days    2018-06-22  11300  11250  11450  10750  134805\n",
      "187 days    2018-06-21  11200  11350  11750  11200  133002\n",
      "188 days    2018-06-20  11550  11200  11600  10900  308596\n",
      "189 days    2018-06-19  11300  11850  11950  11300  180656\n"
     ]
    }
   ],
   "source": [
    "# 시간 간격 계산\n",
    "today = pd.to_datetime('2018-12-25') # 기준일 생성\n",
    "df['time_delta'] = today - df.index\n",
    "df.set_index('time_delta', inplace=True)\n",
    "df_180 = df['180 days':'189 days']\n",
    "print(df_180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
