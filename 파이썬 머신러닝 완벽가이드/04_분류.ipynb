{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 분류의 개요\n",
    "- 지도학습의 대표적인 유형\n",
    "- 학습 데이터로 주어진 데이터의 피처와 레이블값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성하고, 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측하는 것\n",
    "- 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤 새롭게 관측된 데이터에 대한 레이블 판별\n",
    "- 분류를 구현할 수 있는 알고리즘\n",
    "    - 베이즈 통계와 생성 모델에 기반한 나이브 베이즈\n",
    "    - 독립 변수와 종속변수의 선형 관계성에 기반한 로지스틱 회귀\n",
    "    - 데이터 균일도에 따른 규칙 기반 결정 트리\n",
    "    - 개별 클래스 간 최대 분류 마진을 효과적으로 찾아주는 서포트 벡터 머신\n",
    "    - 근접 거리 기준으로 하는 최소 근접 알고리즘\n",
    "    - 심층 연결 기반의 신경망\n",
    "    - 머신러닝 알고리즘 결합한 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**앙상블**\n",
    "- 분류에서 가장 각광받는 방법 중 하나\n",
    "- 정형 데이터의 예측 분석 영역에서 매우 높은 예측 성능을 보임\n",
    "\n",
    "**배깅**\n",
    "- 랜덤 포레스트 → 뛰어난 예측 성능, 상대적으로 빠른 수행 시간, 유연성 등이 장점   \n",
    "    \n",
    "**부스팅**\n",
    "- 최근의 앙상블 방법은 부스팅 방식으로 지속해서 발전중임.\n",
    "- 그래디언트 부스팅 → 예측성능이 뛰어나지만 수행시간이 매우 오래 걸려 최적화 모델 튜딩이 어려움\n",
    "- XgBoost, LightGBM 등 기존 그래디언트 부스팅의 예측 성능 발전시키면서 수행시간 단축시킨 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 결정 트리(Decision Tree)\n",
    "- 매우 쉽고 유연하게 적용될 수 있는 알고리즘\n",
    "- 데이터 스케일링이나 정규화 등 사전 가공의 영향이 매우 적음\n",
    "- 예측 성능 향상을 위해 복잡한 규칙 구조를 가져야 하며, 이로 인한 과적합으로 예측 성능이 저하될 수 있음\n",
    "- 위의 단점이 앙상블 기법에서는 장점으로 작용함 ( 앙상블은 매우 여러개의 약한 학습기(예측 성능이 떨어지는 학습 알고리즘)을 결합헤 확률적으로 보완과 가중치 업데이트로 예측 성능 향상시킴 ) \n",
    "- 결정 트리는 좋은 약한 학습기가 되기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML 알고리즘 중 직관적으로 이해하기 쉬운 알고리즘\n",
    "- 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 Tree 기반의 분류 규칙 만듦.\n",
    "- 어떤 기준을 바탕으로 규칙을 만들어야 가장 효율적인 분류가 될 것인가가 알고리즘의 성능 좌우   \n",
    "\n",
    "**결정 트리 구조**\n",
    "- 규칙 노드(Decision Node) : 규칙 조건\n",
    "- 리프 노드(Leaf Node) : 결정된 클래스 값\n",
    "- 서브 트리(Sub Tree) ; 새로운 규칙 조건마다 생성됨\n",
    "- 트리의 깊이가 깊어질수록 결정 트리의 예측 성능이 저하(과적합)될 가능성이 높음\n",
    "- 가능한 적은 노드로 높은 예측 정확도 가질 수 있도록 하는게 좋음 → 최대한 균일한 데이터 세트를 구성할 수 있도록 분할하는 것이 필요\n",
    "- 결정 노드 : 정보 균일도가 높은 데이터 세트를 먼저 선택할 수 있도록 규칙 조건 만듦.\n",
    "- 균일도 측정 방법\n",
    "    - 엔트로피 이용한 정보 이득 지수(Information Gain)   \n",
    "        : 1 - 엔트로피 지수(주어진 데이터 집합의 혼잡도), 정보 이득이 높은 속성을 기준으로 분할\n",
    "    - 지니 계수   \n",
    "        : 0이 가장 평등하고 1로 갈수록 불평등 , 지니 계수가 낮을수록 균일도가 높은 것으로 해석해 지니 계수가 낮은 속성 기준으로 분할\n",
    "- DecisionTreeClassifier\n",
    "     1. 데이터 집합의 모든 아이템이 같은  분류에 속하는지 확인\n",
    "     2-1. If True : 리프 노드로 만들어 분류 결정\n",
    "     2-2. Else : 데이터 분할하는 데 기장 좋은 석성과 분할 기준 찾음(정보이득/지니계수 이용)\n",
    "     3. 해당 속성과 분할 기준으로 데이터 분할해 Branch 노드 생성\n",
    "     4. Recursive 하게 모든 데이터 집합의 분류가 결정될 때 까지 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정 트리 모델의 특징\n",
    "- 정보의 균일도라는 룰을 기반으로 하기 떄문에 알고리즘이 쉽고 직관적임\n",
    "- 룰이 매우 명확하고, 이를 기반으로 어떻게 규칙노드와 리프노드가 만들어지는지 시각화도 가능\n",
    "- 정보의 균일도만 신경쓰면 되기 때문에 특별한 경우 제외하고 피처 스케일링과 정규화같은 전처리 작업 필요 없음\n",
    "- 단점은 과적합으로 정확도가 떨어짐\n",
    "- 피처가 많고 균일도가 다양하게 존재할수록 트리 깊이가 커지고 복잡해짐 → 트리 크기 사전에 제한하는 것이 성능 튜닝에 도움이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정 트리 파라미터\n",
    "- min_samples_split : 노드 분할하기 위한 최소한의 샘플데이터 수 , 과적합 제어용, 디폴트 = 2 (값이 적을수록 과적합 가능성 증가)\n",
    "- min_samples_leaf : 말단 노드가 되기 위한 최소 샘플 데이터 수 , 과적합 제어용, 비대칭 데이터의 경우 작게 설정할 필요 있음\n",
    "- max_features : 최적의 분할을 위해 고려할 최대 피처 수, 디폴트 = None (int:개수,float:퍼센트,sqrt=auto=sqrt(전체개수),log,None:전체 피처)\n",
    "- max_depth : 트리 최대 깊이 규정\n",
    "- max_leaf_node: 말단 노드의 최대 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정 트리 모델 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=156)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=11)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(dt_clf, out_file='tree.dot', class_names = iris_data.target_names,\n",
    "               feature_names = iris_data.feature_names, impurity=True, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"746pt\" height=\"671pt\"\n",
       " viewBox=\"0.00 0.00 746.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-667 742,-667 742,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#fffdfd\" stroke=\"black\" points=\"272,-663 114,-663 114,-580 272,-580 272,-663\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-647.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal length (cm) &lt;= 2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-632.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-617.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 120</text>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-602.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [41, 40, 39]</text>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-587.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"173,-536.5 61,-536.5 61,-468.5 173,-468.5 173,-536.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-521.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-506.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 41</text>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-491.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [41, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"117\" y=\"-476.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.63,-579.91C159.32,-568.65 151.37,-556.42 144.03,-545.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.93,-543.15 138.54,-536.67 141.06,-546.96 146.93,-543.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.35\" y=\"-557.42\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#fafefc\" stroke=\"black\" points=\"346.5,-544 191.5,-544 191.5,-461 346.5,-461 346.5,-544\"/>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-528.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.55</text>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-513.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-498.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 79</text>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-483.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 40, 39]</text>\n",
       "<text text-anchor=\"middle\" x=\"269\" y=\"-468.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.37,-579.91C225.09,-571.1 231.19,-561.7 237.1,-552.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"240.17,-554.31 242.68,-544.02 234.3,-550.5 240.17,-554.31\"/>\n",
       "<text text-anchor=\"middle\" x=\"247.87\" y=\"-564.78\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#3ee684\" stroke=\"black\" points=\"261,-425 103,-425 103,-342 261,-342 261,-425\"/>\n",
       "<text text-anchor=\"middle\" x=\"182\" y=\"-409.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal length (cm) &lt;= 5.25</text>\n",
       "<text text-anchor=\"middle\" x=\"182\" y=\"-394.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.051</text>\n",
       "<text text-anchor=\"middle\" x=\"182\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 38</text>\n",
       "<text text-anchor=\"middle\" x=\"182\" y=\"-364.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 37, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"182\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.82,-460.91C232.14,-451.92 224.99,-442.32 218.1,-433.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.91,-430.96 212.13,-425.02 215.29,-435.13 220.91,-430.96\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#8b49e7\" stroke=\"black\" points=\"434.5,-425 279.5,-425 279.5,-342 434.5,-342 434.5,-425\"/>\n",
       "<text text-anchor=\"middle\" x=\"357\" y=\"-409.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"357\" y=\"-394.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.136</text>\n",
       "<text text-anchor=\"middle\" x=\"357\" y=\"-379.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 41</text>\n",
       "<text text-anchor=\"middle\" x=\"357\" y=\"-364.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 3, 38]</text>\n",
       "<text text-anchor=\"middle\" x=\"357\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.53,-460.91C306.29,-451.92 313.52,-442.32 320.48,-433.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.31,-435.12 326.52,-425.02 317.71,-430.91 323.31,-435.12\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#39e581\" stroke=\"black\" points=\"116,-298.5 0,-298.5 0,-230.5 116,-230.5 116,-298.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-283.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-268.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 37</text>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-253.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 37, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"58\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.98,-341.91C126.58,-330.21 113.07,-317.46 100.69,-305.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.83,-302.98 93.15,-298.67 98.02,-308.08 102.83,-302.98\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#8139e5\" stroke=\"black\" points=\"241.5,-298.5 134.5,-298.5 134.5,-230.5 241.5,-230.5 241.5,-298.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-283.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-268.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-253.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.08,-341.91C184.63,-331.2 185.22,-319.62 185.78,-308.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.28,-308.83 186.3,-298.67 182.29,-308.47 189.28,-308.83\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"431,-306 271,-306 271,-223 431,-223 431,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sepal length (cm) &lt;= 5.45</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M354.92,-341.91C354.49,-333.56 354.03,-324.67 353.59,-316.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"357.09,-315.83 353.08,-306.02 350.09,-316.19 357.09,-315.83\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#843ee6\" stroke=\"black\" points=\"607,-306 449,-306 449,-223 607,-223 607,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-290.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal length (cm) &lt;= 4.85</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-275.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.053</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-260.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 37</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 36]</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>6&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M416.33,-341.91C430.52,-332.2 445.78,-321.76 460.31,-311.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.5,-314.56 468.78,-306.02 458.55,-308.78 462.5,-314.56\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#8139e5\" stroke=\"black\" points=\"253.5,-179.5 146.5,-179.5 146.5,-111.5 253.5,-111.5 253.5,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-164.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-149.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M298.61,-222.91C283.23,-210.99 266.43,-197.98 251.13,-186.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.85,-183.03 242.81,-179.67 248.57,-188.56 252.85,-183.03\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#9cf2c0\" stroke=\"black\" points=\"430,-187 272,-187 272,-104 430,-104 430,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">petal length (cm) &lt;= 5.45</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"351\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351,-222.91C351,-214.65 351,-205.86 351,-197.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"354.5,-197.02 351,-187.02 347.5,-197.02 354.5,-197.02\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#39e581\" stroke=\"black\" points=\"291,-68 175,-68 175,0 291,0 291,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M307.06,-103.73C297.04,-94.42 286.39,-84.54 276.39,-75.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"278.6,-72.54 268.88,-68.3 273.83,-77.67 278.6,-72.54\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#8139e5\" stroke=\"black\" points=\"416.5,-68 309.5,-68 309.5,0 416.5,0 416.5,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"middle\" x=\"363\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M355.47,-103.73C356.38,-95.43 357.34,-86.67 358.26,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.74,-78.62 359.35,-68.3 354.78,-77.86 361.74,-78.62\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#c09cf2\" stroke=\"black\" points=\"608,-187 448,-187 448,-104 608,-104 608,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-171.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">sepal length (cm) &lt;= 5.95</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-156.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M528,-222.91C528,-214.65 528,-205.86 528,-197.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"531.5,-197.02 528,-187.02 524.5,-197.02 531.5,-197.02\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"#8139e5\" stroke=\"black\" points=\"738,-179.5 626,-179.5 626,-111.5 738,-111.5 738,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-164.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-149.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 34</text>\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 34]</text>\n",
       "<text text-anchor=\"middle\" x=\"682\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>12&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M581.43,-222.91C597.26,-210.88 614.56,-197.73 630.28,-185.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"632.5,-188.5 638.34,-179.67 628.26,-182.93 632.5,-188.5\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#39e581\" stroke=\"black\" points=\"574,-68 458,-68 458,0 574,0 574,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"516\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"516\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"middle\" x=\"516\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"516\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M523.53,-103.73C522.62,-95.43 521.66,-86.67 520.74,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"524.22,-77.86 519.65,-68.3 517.26,-78.62 524.22,-77.86\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"#8139e5\" stroke=\"black\" points=\"699.5,-68 592.5,-68 592.5,0 699.5,0 699.5,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"646\" y=\"-52.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"646\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"middle\" x=\"646\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\n",
       "<text text-anchor=\"middle\" x=\"646\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M571.94,-103.73C581.96,-94.42 592.61,-84.54 602.61,-75.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"605.17,-77.67 610.12,-68.3 600.4,-72.54 605.17,-77.67\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x182dcddd550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "with open('tree.dot') as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.025 0.    0.555 0.42 ]\n",
      "sepal length (cm) : 0.025\n",
      "sepal width (cm) : 0.000\n",
      "petal length (cm) : 0.555\n",
      "petal width (cm) : 0.420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# feature importance 추출\n",
    "print(np.round(dt_clf.feature_importances_,3))\n",
    "\n",
    "# feature 별 importance 매핑\n",
    "for name, value in zip(iris_data.feature_names, dt_clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name,value))\n",
    "\n",
    "# 시각화\n",
    "sns.barplot(x = dt_clf.feature_importances_, y = iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 과적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x182ec35bd60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title('3 Class values with 2 Features Sample data creation')\n",
    "\n",
    "X_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                                          n_classes=3, n_clusters_per_class=1, random_state=0)\n",
    "\n",
    "plt.scatter(X_features[:,0], X_features[:,1], marker='o', c=y_labels, s=25,  edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결정트리 실습 - 사용자 행동 인식 데이터 세트\n",
    "- 30명에게 스마트폰 센서 장착한 뒤 사람의 동작과 관련된 여러 피처 수집한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# features.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있음. 이를 DataFrame으로 로드.\n",
    "feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "\n",
    "# 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\n",
    "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
    "print('전체 피처명에서 10개만 추출:', feature_name[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복된 피처명을 확인\n",
    "\n",
    "feature_dup_df = feature_name_df.groupby('column_name').count()\n",
    "print(feature_dup_df[feature_dup_df['column_index'] > 1].count())\n",
    "feature_dup_df[feature_dup_df['column_index'] > 1].head()\n",
    "\n",
    "#원본 데이터에 중복된 Feature 명으로 인하여 신규 버전의 Pandas에서 Duplicate name 에러를 발생.\n",
    "#중복 feature명에 대해서 원본 feature 명에 '_1(또는2)'를 추가로 부여하는 함수인 get_new_feature_name_df() 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## 학습 피처 데이터셋 info()')\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 예제 반복 시 마다 동일한 예측 결과 도출을 위해 random_state 설정\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))\n",
    "\n",
    "# DecisionTreeClassifier의 하이퍼 파라미터 추출\n",
    "print('DecisionTreeClassifier 기본 하이퍼 파라미터:\\n', dt_clf.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [ 6, 8 ,10, 12, 16 ,20, 24]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치:{0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV객체의 cv_results_ 속성을 DataFrame으로 생성. \n",
    "cv_results_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "# max_depth 파라미터 값과 그때의 테스트(Evaluation)셋, 학습 데이터 셋의 정확도 수치 추출\n",
    "cv_results_df[['param_max_depth', 'mean_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [ 6, 8 ,10, 12, 16 ,20, 24]\n",
    "# max_depth 값을 변화 시키면서 그때마다 학습과 테스트 셋에서의 예측 성능 측정\n",
    "for depth in max_depths:\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=depth, min_samples_split=16, random_state=156)\n",
    "    dt_clf.fit(X_train , y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    print('max_depth = {0} 정확도: {1:.4f}'.format(depth , accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth' : [ 8 , 12, 16 ,20], \n",
    "    'min_samples_split' : [16, 24],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df_clf = grid_cv.best_estimator_\n",
    "pred1 = best_df_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred1)\n",
    "print('결정 트리 예측 정확도:{0:.4f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 앙상블 학습 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 결정 트리에서 사용한 get_human_dataset( )을 이용해 학습/테스트용 DataFrame 반환\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, \\\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('rf_feature_importances_top20.tif', format='tif', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 GBM(Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 아래는 책에서 설명드리지는 않지만 GridSearchCV로 GBM의 하이퍼 파라미터 튜닝을 수행하는 예제 입니다. \n",
    "### 사이킷런이 1.X로 업그레이드 되며서 GBM의 학습 속도가 현저하게 저하되는 문제가 오히려 발생합니다. \n",
    "### 아래는 수행 시간이 오래 걸리므로 참고용으로만 사용하시면 좋을 것 같습니다. \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 500],\n",
    "    'learning_rate' : [ 0.05, 0.1]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost 적용 – 위스콘신 유방암 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_features= dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
    "cancer_df['target']= y_label\n",
    "cancer_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.target_names)\n",
    "print(cancer_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer_df에서 feature용 DataFrame과 Label용 Series 객체 추출\n",
    "# 맨 마지막 칼럼이 Label임. Feature용 DataFrame은 cancer_df의 첫번째 칼럼에서 맨 마지막 두번째 칼럼까지를 :-1 슬라이싱으로 추출.\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,\n",
    "                                         test_size=0.2, random_state=156 )\n",
    "\n",
    "# 위에서 만든 X_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1, random_state=156 )\n",
    "print(X_train.shape , X_test.shape)\n",
    "print(X_tr.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 구버전 XGBoost에서 DataFrame으로 DMatrix 생성이 안될 경우 X_train.values로 넘파이 변환.\n",
    "# 학습, 검증, 테스트용 DMatrix를 생성.\n",
    "dtr = xgb.DMatrix(data=X_tr, label=y_tr)\n",
    "dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(data=X_test , label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { 'max_depth':3,\n",
    "          'eta': 0.05,\n",
    "          'objective':'binary:logistic',\n",
    "          'eval_metric':'logloss'\n",
    "         }\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 셋은 'train' 또는 평가 데이터 셋은 'eval' 로 명기합니다. \n",
    "eval_list = [(dtr,'train'),(dval,'eval')] # 또는 eval_list = [(dval,'eval')] 만 명기해도 무방. \n",
    "\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달\n",
    "xgb_model = xgb.train(params = params , dtrain=dtr , num_boost_round=num_rounds , \\\n",
    "                      early_stopping_rounds=50, evals=eval_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장 \n",
    "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
    "print('예측값 10개만 표시:',preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test , preds, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "plot_importance(xgb_model, ax=ax)\n",
    "plt.savefig('p239_xgb_feature_importance.tif', format='tif', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런 래퍼 XGBoost의 개요 및 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 래퍼 XGBoost 클래스인 XGBClassifier 임포트\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_wrapper.fit(X_train, y_train)\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clf_eval(y_test , w_preds, w_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "evals = [(X_test, y_test)]\n",
    "xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "ws100_preds = xgb_wrapper.predict(X_test)\n",
    "ws100_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_clf_eval(y_test , ws100_preds, ws100_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping_rounds를 10으로 설정하고 재 학습. \n",
    "xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=10, \n",
    "                eval_metric=\"logloss\", eval_set=evals,verbose=True)\n",
    "\n",
    "ws10_preds = xgb_wrapper.predict(X_test)\n",
    "ws10_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "get_clf_eval(y_test , ws10_preds, ws10_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "# 사이킷런 래퍼 클래스를 입력해도 무방. \n",
    "plot_importance(xgb_wrapper, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 앙상블 학습 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 결정 트리에서 사용한 get_human_dataset( )을 이용해 학습/테스트용 DataFrame 반환\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, \\\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('rf_feature_importances_top20.tif', format='tif', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 GBM(Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 아래는 책에서 설명드리지는 않지만 GridSearchCV로 GBM의 하이퍼 파라미터 튜닝을 수행하는 예제 입니다. \n",
    "### 사이킷런이 1.X로 업그레이드 되며서 GBM의 학습 속도가 현저하게 저하되는 문제가 오히려 발생합니다. \n",
    "### 아래는 수행 시간이 오래 걸리므로 참고용으로만 사용하시면 좋을 것 같습니다. \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 500],\n",
    "    'learning_rate' : [ 0.05, 0.1]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.3 앙상블 학습 개요\n",
    "\n",
    "### Voting Classifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)\n",
    "\n",
    "\n",
    "\n",
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))\n",
    "\n",
    "## 4.4 Random Forest\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 결정 트리에서 사용한 get_human_dataset( )을 이용해 학습/테스트용 DataFrame 반환\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "rf_clf1 = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, \\\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('rf_feature_importances_top20.tif', format='tif', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## 4.5 GBM(Gradient Boosting Machine)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "### 아래는 책에서 설명드리지는 않지만 GridSearchCV로 GBM의 하이퍼 파라미터 튜닝을 수행하는 예제 입니다. \n",
    "### 사이킷런이 1.X로 업그레이드 되며서 GBM의 학습 속도가 현저하게 저하되는 문제가 오히려 발생합니다. \n",
    "### 아래는 수행 시간이 오래 걸리므로 참고용으로만 사용하시면 좋을 것 같습니다. \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 500],\n",
    "    'learning_rate' : [ 0.05, 0.1]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))## 4.3 앙상블 학습 개요\n",
    "\n",
    "### Voting Classifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)\n",
    "\n",
    "\n",
    "\n",
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    test_size=0.2 , random_state= 156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))\n",
    "\n",
    "## 4.4 Random Forest\n",
    "\n",
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 결정 트리에서 사용한 get_human_dataset( )을 이용해 학습/테스트용 DataFrame 반환\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth' : [6, 8, 10, 12], \n",
    "    'min_samples_leaf' : [8, 12, 18 ],\n",
    "    'min_samples_split' : [8, 16, 20]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "rf_clf1 = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, \\\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf1.fit(X_train , y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values,index=X_train.columns  )\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "fig1 = plt.gcf()\n",
    "plt.show()\n",
    "plt.draw()\n",
    "fig1.savefig('rf_feature_importances_top20.tif', format='tif', dpi=300, bbox_inches='tight')\n",
    "\n",
    "## 4.5 GBM(Gradient Boosting Machine)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "### 아래는 책에서 설명드리지는 않지만 GridSearchCV로 GBM의 하이퍼 파라미터 튜닝을 수행하는 예제 입니다. \n",
    "### 사이킷런이 1.X로 업그레이드 되며서 GBM의 학습 속도가 현저하게 저하되는 문제가 오히려 발생합니다. \n",
    "### 아래는 수행 시간이 오래 걸리므로 참고용으로만 사용하시면 좋을 것 같습니다. \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100, 500],\n",
    "    'learning_rate' : [ 0.05, 0.1]\n",
    "}\n",
    "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1)\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n",
    "\n",
    "# GridSearchCV를 이용하여 최적으로 학습된 estimator로 predict 수행. \n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))import seaborn as sns\n",
    "\n",
    "ftr_importances_values = best_df_clf.feature_importances_\n",
    "# Top 중요도로 정렬을 쉽게 하고, 시본(Seaborn)의 막대그래프로 쉽게 표현하기 위해 Series변환\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns  )\n",
    "# 중요도값 순으로 Series를 정렬\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
