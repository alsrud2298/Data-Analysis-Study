{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기 및 전처리\n",
    "# 심장 질환 데이터\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "heart = pd.read_csv('./data/heart.csv')\n",
    "\n",
    "#범주형/연속형 변수 분리\n",
    "cat_col = ['sex', 'cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']\n",
    "con_col = ['age', 'trtbps', 'thalachh', 'oldpeak']\n",
    "\n",
    "heart_raw = heart.copy() #원본 데이터 copy\n",
    "\n",
    "#get_dummies()로 범주형 변수 원핫인코딩\n",
    "heart = pd.get_dummies(heart, columns=cat_col, drop_first=True)\n",
    "\n",
    "#train, test, val 분리\n",
    "X = heart.drop(['output'], axis=1)\n",
    "y = heart[['output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 train,test (8:2) 비율로 나눈 후 train 데이터는 다시 train,val (9;1)로 나누시오.(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7377049180327869"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. LGBMClassifier 객체를 생성하고 학습/예측하여 정확도를 측정하시오. (***부분 )\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(num_leaves=31, objective='binary')\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "y_pred = lgb_clf.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### 3. plot_importance 라이브러리를 활용해 피처 중요도 그래프를 그리시오.\n",
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(lgb_clf, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구남이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "citrus_df = pd.read_csv('./data/citrus.csv')\n",
    "y_citrus_df = (citrus_df.name == 'orange').astype(int)\n",
    "X_citrus_df = citrus_df.drop('name', axis=1)\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_citrus_df, y_citrus_df, test_size=0.2, random_state=156 )\n",
    "\n",
    "# 앞에서 추출한 학습 데이터를 다시 학습과 검증 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# 검색 공간 설정\n",
    "# max_depth는 5에서 0까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01애소 0.2사이 정규 분포된 값으로 검색\n",
    "\n",
    "# Q1. 'max_depth', 'min_child_weight'는 정수형 파라미터입니다. ***에 들어가야하는 함수는 무엇인가요?\n",
    "\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   }\n",
    "\n",
    "# 목적 함수 설정\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    # Q2. 목적함수의 반환값을 정확도로 설정할 수 있도록 빈칸을 채워주세요.    \n",
    "    return {'loss': -1*np.mean(accuracy) , 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                               | 1/50 [00:03<02:34,  3.16s/trial, best loss: -0.9502505922693647]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▉                                              | 2/50 [00:04<02:05,  2.62s/trial, best loss: -0.9532501704353722]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▉                                             | 3/50 [00:06<01:52,  2.40s/trial, best loss: -0.9653756708768494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▊                                            | 4/50 [00:08<01:49,  2.38s/trial, best loss: -0.9653756708768494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████▊                                           | 5/50 [00:11<01:57,  2.60s/trial, best loss: -0.9653756708768494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████▊                                          | 6/50 [00:13<01:45,  2.40s/trial, best loss: -0.9653756708768494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████▋                                         | 7/50 [00:16<01:44,  2.44s/trial, best loss: -0.9653756708768494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|███████▋                                        | 8/50 [00:18<01:44,  2.48s/trial, best loss: -0.9658755146229376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|████████▋                                       | 9/50 [00:20<01:34,  2.30s/trial, best loss: -0.9658755146229376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████████▍                                     | 10/50 [00:23<01:31,  2.30s/trial, best loss: -0.9658755146229376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████▎                                    | 11/50 [00:27<01:55,  2.97s/trial, best loss: -0.9658755146229376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████▎                                   | 12/50 [00:30<01:56,  3.07s/trial, best loss: -0.9658755146229376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████▏                                  | 13/50 [00:33<01:47,  2.91s/trial, best loss: -0.9658755146229376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████▏                                 | 14/50 [00:37<02:00,  3.34s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████                                 | 15/50 [00:40<01:52,  3.22s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███████████████                                | 16/50 [00:42<01:34,  2.77s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████▉                               | 17/50 [00:44<01:26,  2.63s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████▉                              | 18/50 [00:47<01:27,  2.73s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████▊                             | 19/50 [00:49<01:17,  2.49s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████▊                            | 20/50 [00:52<01:13,  2.45s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████▋                           | 21/50 [00:55<01:22,  2.85s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████▋                          | 22/50 [00:59<01:27,  3.12s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████▌                         | 23/50 [01:03<01:27,  3.23s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████▌                        | 24/50 [01:06<01:22,  3.18s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████▌                       | 25/50 [01:09<01:20,  3.23s/trial, best loss: -0.9667504052616079]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|████████████████████████▍                      | 26/50 [01:13<01:21,  3.39s/trial, best loss: -0.9678755459393532]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████████████████████████▍                     | 27/50 [01:16<01:18,  3.39s/trial, best loss: -0.9678755459393532]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████▎                    | 28/50 [01:20<01:14,  3.40s/trial, best loss: -0.9692505147284196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████▎                   | 29/50 [01:23<01:11,  3.38s/trial, best loss: -0.9692505147284196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████▏                  | 30/50 [01:26<01:06,  3.33s/trial, best loss: -0.9692505147284196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████▏                 | 31/50 [01:29<01:02,  3.27s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████                 | 32/50 [01:32<00:57,  3.20s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|███████████████████████████████                | 33/50 [01:36<00:54,  3.22s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████▉               | 34/50 [01:40<00:57,  3.60s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████▉              | 35/50 [01:43<00:51,  3.43s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████▊             | 36/50 [01:47<00:50,  3.58s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████▊            | 37/50 [01:51<00:46,  3.61s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████████████████████████████████▋           | 38/50 [01:54<00:42,  3.56s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████████████████▋          | 39/50 [01:58<00:39,  3.60s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████▌         | 40/50 [02:01<00:33,  3.40s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████▌        | 41/50 [02:04<00:31,  3.51s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████▍       | 42/50 [02:07<00:26,  3.34s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████▍      | 43/50 [02:11<00:23,  3.36s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████████▎     | 44/50 [02:15<00:22,  3.73s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████▎    | 45/50 [02:19<00:18,  3.61s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████▏   | 46/50 [02:22<00:13,  3.40s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████▏  | 47/50 [02:25<00:10,  3.37s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████  | 48/50 [02:29<00:06,  3.43s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████ | 49/50 [02:33<00:03,  3.65s/trial, best loss: -0.9697505928788158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [02:38<00:00,  3.16s/trial, best loss: -0.9697505928788158]\n",
      "best: {'colsample_bytree': 0.8605773347266229, 'learning_rate': 0.19696577128383452, 'max_depth': 12.0, 'min_child_weight': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# fmin()함수를 사용해 최적의 하이퍼 파라미터 도출\n",
    "\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "# Q3. 앞에서 설정한 목적함수, 하이퍼 파라미터 검색 공간을 인자로 입력해주세요.\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best)\n",
    "\n",
    "# 최적 하이퍼 파라미터들을 이용해서 XGBClassifier를 재학습한 후 성능 평가 결과를 확인\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.54028\tvalidation_1-logloss:0.54652\n",
      "[1]\tvalidation_0-logloss:0.44035\tvalidation_1-logloss:0.45175\n",
      "[2]\tvalidation_0-logloss:0.35976\tvalidation_1-logloss:0.37458\n",
      "[3]\tvalidation_0-logloss:0.29785\tvalidation_1-logloss:0.31612\n",
      "[4]\tvalidation_0-logloss:0.25025\tvalidation_1-logloss:0.27113\n",
      "[5]\tvalidation_0-logloss:0.21674\tvalidation_1-logloss:0.24335\n",
      "[6]\tvalidation_0-logloss:0.18577\tvalidation_1-logloss:0.21467\n",
      "[7]\tvalidation_0-logloss:0.16078\tvalidation_1-logloss:0.19270\n",
      "[8]\tvalidation_0-logloss:0.14036\tvalidation_1-logloss:0.17541\n",
      "[9]\tvalidation_0-logloss:0.12644\tvalidation_1-logloss:0.16455\n",
      "[10]\tvalidation_0-logloss:0.11425\tvalidation_1-logloss:0.15455\n",
      "[11]\tvalidation_0-logloss:0.10196\tvalidation_1-logloss:0.14372\n",
      "[12]\tvalidation_0-logloss:0.09376\tvalidation_1-logloss:0.13892\n",
      "[13]\tvalidation_0-logloss:0.08534\tvalidation_1-logloss:0.13250\n",
      "[14]\tvalidation_0-logloss:0.07738\tvalidation_1-logloss:0.12654\n",
      "[15]\tvalidation_0-logloss:0.07034\tvalidation_1-logloss:0.12092\n",
      "[16]\tvalidation_0-logloss:0.06595\tvalidation_1-logloss:0.11786\n",
      "[17]\tvalidation_0-logloss:0.06106\tvalidation_1-logloss:0.11502\n",
      "[18]\tvalidation_0-logloss:0.05657\tvalidation_1-logloss:0.11231\n",
      "[19]\tvalidation_0-logloss:0.05301\tvalidation_1-logloss:0.10857\n",
      "[20]\tvalidation_0-logloss:0.05011\tvalidation_1-logloss:0.10599\n",
      "[21]\tvalidation_0-logloss:0.04760\tvalidation_1-logloss:0.10464\n",
      "[22]\tvalidation_0-logloss:0.04518\tvalidation_1-logloss:0.10408\n",
      "[23]\tvalidation_0-logloss:0.04322\tvalidation_1-logloss:0.10354\n",
      "[24]\tvalidation_0-logloss:0.04171\tvalidation_1-logloss:0.10237\n",
      "[25]\tvalidation_0-logloss:0.04048\tvalidation_1-logloss:0.10100\n",
      "[26]\tvalidation_0-logloss:0.03858\tvalidation_1-logloss:0.10032\n",
      "[27]\tvalidation_0-logloss:0.03783\tvalidation_1-logloss:0.09913\n",
      "[28]\tvalidation_0-logloss:0.03665\tvalidation_1-logloss:0.09923\n",
      "[29]\tvalidation_0-logloss:0.03471\tvalidation_1-logloss:0.09694\n",
      "[30]\tvalidation_0-logloss:0.03418\tvalidation_1-logloss:0.09608\n",
      "[31]\tvalidation_0-logloss:0.03308\tvalidation_1-logloss:0.09555\n",
      "[32]\tvalidation_0-logloss:0.03230\tvalidation_1-logloss:0.09551\n",
      "[33]\tvalidation_0-logloss:0.03145\tvalidation_1-logloss:0.09506\n",
      "[34]\tvalidation_0-logloss:0.03104\tvalidation_1-logloss:0.09506\n",
      "[35]\tvalidation_0-logloss:0.03015\tvalidation_1-logloss:0.09548\n",
      "[36]\tvalidation_0-logloss:0.02983\tvalidation_1-logloss:0.09548\n",
      "[37]\tvalidation_0-logloss:0.02842\tvalidation_1-logloss:0.09287\n",
      "[38]\tvalidation_0-logloss:0.02767\tvalidation_1-logloss:0.09335\n",
      "[39]\tvalidation_0-logloss:0.02741\tvalidation_1-logloss:0.09348\n",
      "[40]\tvalidation_0-logloss:0.02667\tvalidation_1-logloss:0.09450\n",
      "[41]\tvalidation_0-logloss:0.02643\tvalidation_1-logloss:0.09400\n",
      "[42]\tvalidation_0-logloss:0.02548\tvalidation_1-logloss:0.09312\n",
      "[43]\tvalidation_0-logloss:0.02525\tvalidation_1-logloss:0.09295\n",
      "[44]\tvalidation_0-logloss:0.02497\tvalidation_1-logloss:0.09283\n",
      "[45]\tvalidation_0-logloss:0.02451\tvalidation_1-logloss:0.09329\n",
      "[46]\tvalidation_0-logloss:0.02399\tvalidation_1-logloss:0.09409\n",
      "[47]\tvalidation_0-logloss:0.02372\tvalidation_1-logloss:0.09423\n",
      "[48]\tvalidation_0-logloss:0.02321\tvalidation_1-logloss:0.09421\n",
      "[49]\tvalidation_0-logloss:0.02271\tvalidation_1-logloss:0.09502\n",
      "[50]\tvalidation_0-logloss:0.02209\tvalidation_1-logloss:0.09423\n",
      "[51]\tvalidation_0-logloss:0.02168\tvalidation_1-logloss:0.09461\n",
      "[52]\tvalidation_0-logloss:0.02116\tvalidation_1-logloss:0.09416\n",
      "[53]\tvalidation_0-logloss:0.02069\tvalidation_1-logloss:0.09411\n",
      "[54]\tvalidation_0-logloss:0.02035\tvalidation_1-logloss:0.09327\n",
      "[55]\tvalidation_0-logloss:0.01999\tvalidation_1-logloss:0.09387\n",
      "[56]\tvalidation_0-logloss:0.01957\tvalidation_1-logloss:0.09410\n",
      "[57]\tvalidation_0-logloss:0.01929\tvalidation_1-logloss:0.09430\n",
      "[58]\tvalidation_0-logloss:0.01824\tvalidation_1-logloss:0.09145\n",
      "[59]\tvalidation_0-logloss:0.01796\tvalidation_1-logloss:0.09093\n",
      "[60]\tvalidation_0-logloss:0.01715\tvalidation_1-logloss:0.08868\n",
      "[61]\tvalidation_0-logloss:0.01636\tvalidation_1-logloss:0.08690\n",
      "[62]\tvalidation_0-logloss:0.01616\tvalidation_1-logloss:0.08691\n",
      "[63]\tvalidation_0-logloss:0.01556\tvalidation_1-logloss:0.08483\n",
      "[64]\tvalidation_0-logloss:0.01538\tvalidation_1-logloss:0.08470\n",
      "[65]\tvalidation_0-logloss:0.01480\tvalidation_1-logloss:0.08281\n",
      "[66]\tvalidation_0-logloss:0.01456\tvalidation_1-logloss:0.08292\n",
      "[67]\tvalidation_0-logloss:0.01412\tvalidation_1-logloss:0.08186\n",
      "[68]\tvalidation_0-logloss:0.01396\tvalidation_1-logloss:0.08237\n",
      "[69]\tvalidation_0-logloss:0.01386\tvalidation_1-logloss:0.08255\n",
      "[70]\tvalidation_0-logloss:0.01349\tvalidation_1-logloss:0.08171\n",
      "[71]\tvalidation_0-logloss:0.01318\tvalidation_1-logloss:0.08117\n",
      "[72]\tvalidation_0-logloss:0.01300\tvalidation_1-logloss:0.08128\n",
      "[73]\tvalidation_0-logloss:0.01269\tvalidation_1-logloss:0.08112\n",
      "[74]\tvalidation_0-logloss:0.01253\tvalidation_1-logloss:0.08073\n",
      "[75]\tvalidation_0-logloss:0.01208\tvalidation_1-logloss:0.07928\n",
      "[76]\tvalidation_0-logloss:0.01191\tvalidation_1-logloss:0.07931\n",
      "[77]\tvalidation_0-logloss:0.01177\tvalidation_1-logloss:0.07933\n",
      "[78]\tvalidation_0-logloss:0.01142\tvalidation_1-logloss:0.07802\n",
      "[79]\tvalidation_0-logloss:0.01129\tvalidation_1-logloss:0.07802\n",
      "[80]\tvalidation_0-logloss:0.01115\tvalidation_1-logloss:0.07888\n",
      "[81]\tvalidation_0-logloss:0.01104\tvalidation_1-logloss:0.07859\n",
      "[82]\tvalidation_0-logloss:0.01090\tvalidation_1-logloss:0.07893\n",
      "[83]\tvalidation_0-logloss:0.01077\tvalidation_1-logloss:0.07941\n",
      "[84]\tvalidation_0-logloss:0.01065\tvalidation_1-logloss:0.07934\n",
      "[85]\tvalidation_0-logloss:0.01054\tvalidation_1-logloss:0.07930\n",
      "[86]\tvalidation_0-logloss:0.01044\tvalidation_1-logloss:0.07898\n",
      "[87]\tvalidation_0-logloss:0.01013\tvalidation_1-logloss:0.07827\n",
      "[88]\tvalidation_0-logloss:0.01004\tvalidation_1-logloss:0.07815\n",
      "[89]\tvalidation_0-logloss:0.00994\tvalidation_1-logloss:0.07789\n",
      "[90]\tvalidation_0-logloss:0.00981\tvalidation_1-logloss:0.07771\n",
      "[91]\tvalidation_0-logloss:0.00970\tvalidation_1-logloss:0.07817\n",
      "[92]\tvalidation_0-logloss:0.00958\tvalidation_1-logloss:0.07828\n",
      "[93]\tvalidation_0-logloss:0.00949\tvalidation_1-logloss:0.07840\n",
      "[94]\tvalidation_0-logloss:0.00941\tvalidation_1-logloss:0.07787\n",
      "[95]\tvalidation_0-logloss:0.00928\tvalidation_1-logloss:0.07804\n",
      "[96]\tvalidation_0-logloss:0.00916\tvalidation_1-logloss:0.07847\n",
      "[97]\tvalidation_0-logloss:0.00906\tvalidation_1-logloss:0.07849\n",
      "[98]\tvalidation_0-logloss:0.00898\tvalidation_1-logloss:0.07835\n",
      "[99]\tvalidation_0-logloss:0.00889\tvalidation_1-logloss:0.07816\n",
      "[100]\tvalidation_0-logloss:0.00868\tvalidation_1-logloss:0.07807\n",
      "[101]\tvalidation_0-logloss:0.00852\tvalidation_1-logloss:0.07813\n",
      "[102]\tvalidation_0-logloss:0.00844\tvalidation_1-logloss:0.07786\n",
      "[103]\tvalidation_0-logloss:0.00838\tvalidation_1-logloss:0.07750\n",
      "[104]\tvalidation_0-logloss:0.00830\tvalidation_1-logloss:0.07729\n",
      "[105]\tvalidation_0-logloss:0.00823\tvalidation_1-logloss:0.07751\n",
      "[106]\tvalidation_0-logloss:0.00816\tvalidation_1-logloss:0.07750\n",
      "[107]\tvalidation_0-logloss:0.00810\tvalidation_1-logloss:0.07751\n",
      "[108]\tvalidation_0-logloss:0.00804\tvalidation_1-logloss:0.07786\n",
      "[109]\tvalidation_0-logloss:0.00798\tvalidation_1-logloss:0.07812\n",
      "[110]\tvalidation_0-logloss:0.00793\tvalidation_1-logloss:0.07838\n",
      "[111]\tvalidation_0-logloss:0.00788\tvalidation_1-logloss:0.07867\n",
      "[112]\tvalidation_0-logloss:0.00780\tvalidation_1-logloss:0.07834\n",
      "[113]\tvalidation_0-logloss:0.00772\tvalidation_1-logloss:0.07803\n",
      "[114]\tvalidation_0-logloss:0.00766\tvalidation_1-logloss:0.07781\n",
      "[115]\tvalidation_0-logloss:0.00755\tvalidation_1-logloss:0.07745\n",
      "[116]\tvalidation_0-logloss:0.00749\tvalidation_1-logloss:0.07754\n",
      "[117]\tvalidation_0-logloss:0.00742\tvalidation_1-logloss:0.07767\n",
      "[118]\tvalidation_0-logloss:0.00736\tvalidation_1-logloss:0.07784\n",
      "[119]\tvalidation_0-logloss:0.00730\tvalidation_1-logloss:0.07789\n",
      "[120]\tvalidation_0-logloss:0.00725\tvalidation_1-logloss:0.07799\n",
      "[121]\tvalidation_0-logloss:0.00721\tvalidation_1-logloss:0.07788\n",
      "[122]\tvalidation_0-logloss:0.00715\tvalidation_1-logloss:0.07773\n",
      "[123]\tvalidation_0-logloss:0.00709\tvalidation_1-logloss:0.07776\n",
      "[124]\tvalidation_0-logloss:0.00704\tvalidation_1-logloss:0.07786\n",
      "[125]\tvalidation_0-logloss:0.00688\tvalidation_1-logloss:0.07713\n",
      "[126]\tvalidation_0-logloss:0.00683\tvalidation_1-logloss:0.07697\n",
      "[127]\tvalidation_0-logloss:0.00669\tvalidation_1-logloss:0.07638\n",
      "[128]\tvalidation_0-logloss:0.00664\tvalidation_1-logloss:0.07599\n",
      "[129]\tvalidation_0-logloss:0.00659\tvalidation_1-logloss:0.07566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130]\tvalidation_0-logloss:0.00649\tvalidation_1-logloss:0.07542\n",
      "[131]\tvalidation_0-logloss:0.00646\tvalidation_1-logloss:0.07529\n",
      "[132]\tvalidation_0-logloss:0.00642\tvalidation_1-logloss:0.07554\n",
      "[133]\tvalidation_0-logloss:0.00637\tvalidation_1-logloss:0.07546\n",
      "[134]\tvalidation_0-logloss:0.00633\tvalidation_1-logloss:0.07552\n",
      "[135]\tvalidation_0-logloss:0.00628\tvalidation_1-logloss:0.07522\n",
      "[136]\tvalidation_0-logloss:0.00624\tvalidation_1-logloss:0.07496\n",
      "[137]\tvalidation_0-logloss:0.00619\tvalidation_1-logloss:0.07506\n",
      "[138]\tvalidation_0-logloss:0.00616\tvalidation_1-logloss:0.07516\n",
      "[139]\tvalidation_0-logloss:0.00613\tvalidation_1-logloss:0.07511\n",
      "[140]\tvalidation_0-logloss:0.00610\tvalidation_1-logloss:0.07542\n",
      "[141]\tvalidation_0-logloss:0.00605\tvalidation_1-logloss:0.07527\n",
      "[142]\tvalidation_0-logloss:0.00601\tvalidation_1-logloss:0.07517\n",
      "[143]\tvalidation_0-logloss:0.00597\tvalidation_1-logloss:0.07495\n",
      "[144]\tvalidation_0-logloss:0.00592\tvalidation_1-logloss:0.07470\n",
      "[145]\tvalidation_0-logloss:0.00583\tvalidation_1-logloss:0.07411\n",
      "[146]\tvalidation_0-logloss:0.00580\tvalidation_1-logloss:0.07391\n",
      "[147]\tvalidation_0-logloss:0.00578\tvalidation_1-logloss:0.07383\n",
      "[148]\tvalidation_0-logloss:0.00574\tvalidation_1-logloss:0.07355\n",
      "[149]\tvalidation_0-logloss:0.00569\tvalidation_1-logloss:0.07342\n",
      "[150]\tvalidation_0-logloss:0.00561\tvalidation_1-logloss:0.07332\n",
      "[151]\tvalidation_0-logloss:0.00557\tvalidation_1-logloss:0.07318\n",
      "[152]\tvalidation_0-logloss:0.00554\tvalidation_1-logloss:0.07353\n",
      "[153]\tvalidation_0-logloss:0.00551\tvalidation_1-logloss:0.07328\n",
      "[154]\tvalidation_0-logloss:0.00549\tvalidation_1-logloss:0.07333\n",
      "[155]\tvalidation_0-logloss:0.00545\tvalidation_1-logloss:0.07300\n",
      "[156]\tvalidation_0-logloss:0.00542\tvalidation_1-logloss:0.07298\n",
      "[157]\tvalidation_0-logloss:0.00539\tvalidation_1-logloss:0.07290\n",
      "[158]\tvalidation_0-logloss:0.00536\tvalidation_1-logloss:0.07276\n",
      "[159]\tvalidation_0-logloss:0.00534\tvalidation_1-logloss:0.07310\n",
      "[160]\tvalidation_0-logloss:0.00531\tvalidation_1-logloss:0.07353\n",
      "[161]\tvalidation_0-logloss:0.00529\tvalidation_1-logloss:0.07367\n",
      "[162]\tvalidation_0-logloss:0.00525\tvalidation_1-logloss:0.07335\n",
      "[163]\tvalidation_0-logloss:0.00522\tvalidation_1-logloss:0.07330\n",
      "[164]\tvalidation_0-logloss:0.00519\tvalidation_1-logloss:0.07341\n",
      "[165]\tvalidation_0-logloss:0.00515\tvalidation_1-logloss:0.07321\n",
      "[166]\tvalidation_0-logloss:0.00512\tvalidation_1-logloss:0.07339\n",
      "[167]\tvalidation_0-logloss:0.00510\tvalidation_1-logloss:0.07335\n",
      "[168]\tvalidation_0-logloss:0.00507\tvalidation_1-logloss:0.07300\n",
      "[169]\tvalidation_0-logloss:0.00504\tvalidation_1-logloss:0.07302\n",
      "[170]\tvalidation_0-logloss:0.00501\tvalidation_1-logloss:0.07334\n",
      "[171]\tvalidation_0-logloss:0.00498\tvalidation_1-logloss:0.07342\n",
      "[172]\tvalidation_0-logloss:0.00495\tvalidation_1-logloss:0.07351\n",
      "[173]\tvalidation_0-logloss:0.00493\tvalidation_1-logloss:0.07362\n",
      "[174]\tvalidation_0-logloss:0.00491\tvalidation_1-logloss:0.07367\n",
      "[175]\tvalidation_0-logloss:0.00489\tvalidation_1-logloss:0.07400\n",
      "[176]\tvalidation_0-logloss:0.00487\tvalidation_1-logloss:0.07405\n",
      "[177]\tvalidation_0-logloss:0.00485\tvalidation_1-logloss:0.07407\n",
      "[178]\tvalidation_0-logloss:0.00483\tvalidation_1-logloss:0.07414\n",
      "[179]\tvalidation_0-logloss:0.00479\tvalidation_1-logloss:0.07382\n",
      "[180]\tvalidation_0-logloss:0.00476\tvalidation_1-logloss:0.07358\n",
      "[181]\tvalidation_0-logloss:0.00472\tvalidation_1-logloss:0.07357\n",
      "[182]\tvalidation_0-logloss:0.00468\tvalidation_1-logloss:0.07353\n",
      "[183]\tvalidation_0-logloss:0.00466\tvalidation_1-logloss:0.07363\n",
      "[184]\tvalidation_0-logloss:0.00465\tvalidation_1-logloss:0.07373\n",
      "[185]\tvalidation_0-logloss:0.00462\tvalidation_1-logloss:0.07357\n",
      "[186]\tvalidation_0-logloss:0.00460\tvalidation_1-logloss:0.07364\n",
      "[187]\tvalidation_0-logloss:0.00459\tvalidation_1-logloss:0.07355\n",
      "[188]\tvalidation_0-logloss:0.00456\tvalidation_1-logloss:0.07332\n",
      "[189]\tvalidation_0-logloss:0.00454\tvalidation_1-logloss:0.07303\n",
      "[190]\tvalidation_0-logloss:0.00452\tvalidation_1-logloss:0.07302\n",
      "[191]\tvalidation_0-logloss:0.00451\tvalidation_1-logloss:0.07321\n",
      "[192]\tvalidation_0-logloss:0.00448\tvalidation_1-logloss:0.07318\n",
      "[193]\tvalidation_0-logloss:0.00445\tvalidation_1-logloss:0.07304\n",
      "[194]\tvalidation_0-logloss:0.00444\tvalidation_1-logloss:0.07315\n",
      "[195]\tvalidation_0-logloss:0.00442\tvalidation_1-logloss:0.07296\n",
      "[196]\tvalidation_0-logloss:0.00439\tvalidation_1-logloss:0.07275\n",
      "[197]\tvalidation_0-logloss:0.00438\tvalidation_1-logloss:0.07278\n",
      "[198]\tvalidation_0-logloss:0.00436\tvalidation_1-logloss:0.07266\n",
      "[199]\tvalidation_0-logloss:0.00433\tvalidation_1-logloss:0.07268\n",
      "[200]\tvalidation_0-logloss:0.00432\tvalidation_1-logloss:0.07279\n",
      "[201]\tvalidation_0-logloss:0.00430\tvalidation_1-logloss:0.07267\n",
      "[202]\tvalidation_0-logloss:0.00429\tvalidation_1-logloss:0.07264\n",
      "[203]\tvalidation_0-logloss:0.00427\tvalidation_1-logloss:0.07279\n",
      "[204]\tvalidation_0-logloss:0.00424\tvalidation_1-logloss:0.07267\n",
      "[205]\tvalidation_0-logloss:0.00421\tvalidation_1-logloss:0.07247\n",
      "[206]\tvalidation_0-logloss:0.00419\tvalidation_1-logloss:0.07215\n",
      "[207]\tvalidation_0-logloss:0.00416\tvalidation_1-logloss:0.07194\n",
      "[208]\tvalidation_0-logloss:0.00414\tvalidation_1-logloss:0.07188\n",
      "[209]\tvalidation_0-logloss:0.00412\tvalidation_1-logloss:0.07177\n",
      "[210]\tvalidation_0-logloss:0.00411\tvalidation_1-logloss:0.07197\n",
      "[211]\tvalidation_0-logloss:0.00409\tvalidation_1-logloss:0.07188\n",
      "[212]\tvalidation_0-logloss:0.00407\tvalidation_1-logloss:0.07177\n",
      "[213]\tvalidation_0-logloss:0.00405\tvalidation_1-logloss:0.07177\n",
      "[214]\tvalidation_0-logloss:0.00403\tvalidation_1-logloss:0.07163\n",
      "[215]\tvalidation_0-logloss:0.00402\tvalidation_1-logloss:0.07165\n",
      "[216]\tvalidation_0-logloss:0.00401\tvalidation_1-logloss:0.07152\n",
      "[217]\tvalidation_0-logloss:0.00399\tvalidation_1-logloss:0.07155\n",
      "[218]\tvalidation_0-logloss:0.00398\tvalidation_1-logloss:0.07165\n",
      "[219]\tvalidation_0-logloss:0.00397\tvalidation_1-logloss:0.07165\n",
      "[220]\tvalidation_0-logloss:0.00395\tvalidation_1-logloss:0.07150\n",
      "[221]\tvalidation_0-logloss:0.00393\tvalidation_1-logloss:0.07151\n",
      "[222]\tvalidation_0-logloss:0.00392\tvalidation_1-logloss:0.07148\n",
      "[223]\tvalidation_0-logloss:0.00390\tvalidation_1-logloss:0.07106\n",
      "[224]\tvalidation_0-logloss:0.00388\tvalidation_1-logloss:0.07101\n",
      "[225]\tvalidation_0-logloss:0.00386\tvalidation_1-logloss:0.07105\n",
      "[226]\tvalidation_0-logloss:0.00386\tvalidation_1-logloss:0.07112\n",
      "[227]\tvalidation_0-logloss:0.00384\tvalidation_1-logloss:0.07112\n",
      "[228]\tvalidation_0-logloss:0.00382\tvalidation_1-logloss:0.07105\n",
      "[229]\tvalidation_0-logloss:0.00381\tvalidation_1-logloss:0.07117\n",
      "[230]\tvalidation_0-logloss:0.00380\tvalidation_1-logloss:0.07124\n",
      "[231]\tvalidation_0-logloss:0.00378\tvalidation_1-logloss:0.07110\n",
      "[232]\tvalidation_0-logloss:0.00376\tvalidation_1-logloss:0.07082\n",
      "[233]\tvalidation_0-logloss:0.00375\tvalidation_1-logloss:0.07065\n",
      "[234]\tvalidation_0-logloss:0.00374\tvalidation_1-logloss:0.07061\n",
      "[235]\tvalidation_0-logloss:0.00373\tvalidation_1-logloss:0.07066\n",
      "[236]\tvalidation_0-logloss:0.00371\tvalidation_1-logloss:0.07055\n",
      "[237]\tvalidation_0-logloss:0.00368\tvalidation_1-logloss:0.07046\n",
      "[238]\tvalidation_0-logloss:0.00368\tvalidation_1-logloss:0.07045\n",
      "[239]\tvalidation_0-logloss:0.00366\tvalidation_1-logloss:0.07049\n",
      "[240]\tvalidation_0-logloss:0.00364\tvalidation_1-logloss:0.07050\n",
      "[241]\tvalidation_0-logloss:0.00362\tvalidation_1-logloss:0.07027\n",
      "[242]\tvalidation_0-logloss:0.00361\tvalidation_1-logloss:0.07008\n",
      "[243]\tvalidation_0-logloss:0.00359\tvalidation_1-logloss:0.06985\n",
      "[244]\tvalidation_0-logloss:0.00358\tvalidation_1-logloss:0.06987\n",
      "[245]\tvalidation_0-logloss:0.00358\tvalidation_1-logloss:0.06983\n",
      "[246]\tvalidation_0-logloss:0.00356\tvalidation_1-logloss:0.06989\n",
      "[247]\tvalidation_0-logloss:0.00355\tvalidation_1-logloss:0.07003\n",
      "[248]\tvalidation_0-logloss:0.00354\tvalidation_1-logloss:0.07006\n",
      "[249]\tvalidation_0-logloss:0.00352\tvalidation_1-logloss:0.06996\n",
      "[250]\tvalidation_0-logloss:0.00351\tvalidation_1-logloss:0.06978\n",
      "[251]\tvalidation_0-logloss:0.00349\tvalidation_1-logloss:0.06962\n",
      "[252]\tvalidation_0-logloss:0.00348\tvalidation_1-logloss:0.06940\n",
      "[253]\tvalidation_0-logloss:0.00346\tvalidation_1-logloss:0.06938\n",
      "[254]\tvalidation_0-logloss:0.00345\tvalidation_1-logloss:0.06930\n",
      "[255]\tvalidation_0-logloss:0.00343\tvalidation_1-logloss:0.06917\n",
      "[256]\tvalidation_0-logloss:0.00342\tvalidation_1-logloss:0.06922\n",
      "[257]\tvalidation_0-logloss:0.00341\tvalidation_1-logloss:0.06924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258]\tvalidation_0-logloss:0.00340\tvalidation_1-logloss:0.06927\n",
      "[259]\tvalidation_0-logloss:0.00339\tvalidation_1-logloss:0.06933\n",
      "[260]\tvalidation_0-logloss:0.00337\tvalidation_1-logloss:0.06929\n",
      "[261]\tvalidation_0-logloss:0.00336\tvalidation_1-logloss:0.06909\n",
      "[262]\tvalidation_0-logloss:0.00335\tvalidation_1-logloss:0.06906\n",
      "[263]\tvalidation_0-logloss:0.00334\tvalidation_1-logloss:0.06893\n",
      "[264]\tvalidation_0-logloss:0.00333\tvalidation_1-logloss:0.06908\n",
      "[265]\tvalidation_0-logloss:0.00331\tvalidation_1-logloss:0.06893\n",
      "[266]\tvalidation_0-logloss:0.00331\tvalidation_1-logloss:0.06884\n",
      "[267]\tvalidation_0-logloss:0.00330\tvalidation_1-logloss:0.06898\n",
      "[268]\tvalidation_0-logloss:0.00329\tvalidation_1-logloss:0.06905\n",
      "[269]\tvalidation_0-logloss:0.00328\tvalidation_1-logloss:0.06919\n",
      "[270]\tvalidation_0-logloss:0.00326\tvalidation_1-logloss:0.06914\n",
      "[271]\tvalidation_0-logloss:0.00326\tvalidation_1-logloss:0.06916\n",
      "[272]\tvalidation_0-logloss:0.00324\tvalidation_1-logloss:0.06895\n",
      "[273]\tvalidation_0-logloss:0.00323\tvalidation_1-logloss:0.06886\n",
      "[274]\tvalidation_0-logloss:0.00321\tvalidation_1-logloss:0.06892\n",
      "[275]\tvalidation_0-logloss:0.00321\tvalidation_1-logloss:0.06897\n",
      "[276]\tvalidation_0-logloss:0.00319\tvalidation_1-logloss:0.06879\n",
      "[277]\tvalidation_0-logloss:0.00319\tvalidation_1-logloss:0.06876\n",
      "[278]\tvalidation_0-logloss:0.00318\tvalidation_1-logloss:0.06867\n",
      "[279]\tvalidation_0-logloss:0.00317\tvalidation_1-logloss:0.06876\n",
      "[280]\tvalidation_0-logloss:0.00316\tvalidation_1-logloss:0.06879\n",
      "[281]\tvalidation_0-logloss:0.00315\tvalidation_1-logloss:0.06879\n",
      "[282]\tvalidation_0-logloss:0.00315\tvalidation_1-logloss:0.06872\n",
      "[283]\tvalidation_0-logloss:0.00314\tvalidation_1-logloss:0.06855\n",
      "[284]\tvalidation_0-logloss:0.00312\tvalidation_1-logloss:0.06858\n",
      "[285]\tvalidation_0-logloss:0.00311\tvalidation_1-logloss:0.06850\n",
      "[286]\tvalidation_0-logloss:0.00310\tvalidation_1-logloss:0.06836\n",
      "[287]\tvalidation_0-logloss:0.00309\tvalidation_1-logloss:0.06817\n",
      "[288]\tvalidation_0-logloss:0.00308\tvalidation_1-logloss:0.06827\n",
      "[289]\tvalidation_0-logloss:0.00307\tvalidation_1-logloss:0.06812\n",
      "[290]\tvalidation_0-logloss:0.00306\tvalidation_1-logloss:0.06816\n",
      "[291]\tvalidation_0-logloss:0.00305\tvalidation_1-logloss:0.06818\n",
      "[292]\tvalidation_0-logloss:0.00304\tvalidation_1-logloss:0.06825\n",
      "[293]\tvalidation_0-logloss:0.00303\tvalidation_1-logloss:0.06813\n",
      "[294]\tvalidation_0-logloss:0.00302\tvalidation_1-logloss:0.06813\n",
      "[295]\tvalidation_0-logloss:0.00301\tvalidation_1-logloss:0.06809\n",
      "[296]\tvalidation_0-logloss:0.00300\tvalidation_1-logloss:0.06811\n",
      "[297]\tvalidation_0-logloss:0.00300\tvalidation_1-logloss:0.06823\n",
      "[298]\tvalidation_0-logloss:0.00299\tvalidation_1-logloss:0.06819\n",
      "[299]\tvalidation_0-logloss:0.00298\tvalidation_1-logloss:0.06803\n",
      "[300]\tvalidation_0-logloss:0.00298\tvalidation_1-logloss:0.06802\n",
      "[301]\tvalidation_0-logloss:0.00297\tvalidation_1-logloss:0.06786\n",
      "[302]\tvalidation_0-logloss:0.00296\tvalidation_1-logloss:0.06786\n",
      "[303]\tvalidation_0-logloss:0.00295\tvalidation_1-logloss:0.06779\n",
      "[304]\tvalidation_0-logloss:0.00294\tvalidation_1-logloss:0.06788\n",
      "[305]\tvalidation_0-logloss:0.00293\tvalidation_1-logloss:0.06799\n",
      "[306]\tvalidation_0-logloss:0.00292\tvalidation_1-logloss:0.06804\n",
      "[307]\tvalidation_0-logloss:0.00292\tvalidation_1-logloss:0.06802\n",
      "[308]\tvalidation_0-logloss:0.00291\tvalidation_1-logloss:0.06793\n",
      "[309]\tvalidation_0-logloss:0.00290\tvalidation_1-logloss:0.06782\n",
      "[310]\tvalidation_0-logloss:0.00290\tvalidation_1-logloss:0.06777\n",
      "[311]\tvalidation_0-logloss:0.00289\tvalidation_1-logloss:0.06785\n",
      "[312]\tvalidation_0-logloss:0.00288\tvalidation_1-logloss:0.06800\n",
      "[313]\tvalidation_0-logloss:0.00288\tvalidation_1-logloss:0.06803\n",
      "[314]\tvalidation_0-logloss:0.00287\tvalidation_1-logloss:0.06781\n",
      "[315]\tvalidation_0-logloss:0.00286\tvalidation_1-logloss:0.06778\n",
      "[316]\tvalidation_0-logloss:0.00285\tvalidation_1-logloss:0.06782\n",
      "[317]\tvalidation_0-logloss:0.00284\tvalidation_1-logloss:0.06782\n",
      "[318]\tvalidation_0-logloss:0.00283\tvalidation_1-logloss:0.06771\n",
      "[319]\tvalidation_0-logloss:0.00283\tvalidation_1-logloss:0.06760\n",
      "[320]\tvalidation_0-logloss:0.00282\tvalidation_1-logloss:0.06766\n",
      "[321]\tvalidation_0-logloss:0.00281\tvalidation_1-logloss:0.06768\n",
      "[322]\tvalidation_0-logloss:0.00280\tvalidation_1-logloss:0.06769\n",
      "[323]\tvalidation_0-logloss:0.00280\tvalidation_1-logloss:0.06778\n",
      "[324]\tvalidation_0-logloss:0.00280\tvalidation_1-logloss:0.06787\n",
      "[325]\tvalidation_0-logloss:0.00279\tvalidation_1-logloss:0.06790\n",
      "[326]\tvalidation_0-logloss:0.00278\tvalidation_1-logloss:0.06789\n",
      "[327]\tvalidation_0-logloss:0.00278\tvalidation_1-logloss:0.06803\n",
      "[328]\tvalidation_0-logloss:0.00277\tvalidation_1-logloss:0.06798\n",
      "[329]\tvalidation_0-logloss:0.00276\tvalidation_1-logloss:0.06797\n",
      "[330]\tvalidation_0-logloss:0.00275\tvalidation_1-logloss:0.06786\n",
      "[331]\tvalidation_0-logloss:0.00274\tvalidation_1-logloss:0.06787\n",
      "[332]\tvalidation_0-logloss:0.00274\tvalidation_1-logloss:0.06784\n",
      "[333]\tvalidation_0-logloss:0.00273\tvalidation_1-logloss:0.06767\n",
      "[334]\tvalidation_0-logloss:0.00272\tvalidation_1-logloss:0.06760\n",
      "[335]\tvalidation_0-logloss:0.00271\tvalidation_1-logloss:0.06750\n",
      "[336]\tvalidation_0-logloss:0.00270\tvalidation_1-logloss:0.06761\n",
      "[337]\tvalidation_0-logloss:0.00270\tvalidation_1-logloss:0.06743\n",
      "[338]\tvalidation_0-logloss:0.00269\tvalidation_1-logloss:0.06752\n",
      "[339]\tvalidation_0-logloss:0.00268\tvalidation_1-logloss:0.06748\n",
      "[340]\tvalidation_0-logloss:0.00267\tvalidation_1-logloss:0.06732\n",
      "[341]\tvalidation_0-logloss:0.00267\tvalidation_1-logloss:0.06719\n",
      "[342]\tvalidation_0-logloss:0.00266\tvalidation_1-logloss:0.06726\n",
      "[343]\tvalidation_0-logloss:0.00266\tvalidation_1-logloss:0.06718\n",
      "[344]\tvalidation_0-logloss:0.00265\tvalidation_1-logloss:0.06717\n",
      "[345]\tvalidation_0-logloss:0.00265\tvalidation_1-logloss:0.06722\n",
      "[346]\tvalidation_0-logloss:0.00264\tvalidation_1-logloss:0.06723\n",
      "[347]\tvalidation_0-logloss:0.00263\tvalidation_1-logloss:0.06718\n",
      "[348]\tvalidation_0-logloss:0.00263\tvalidation_1-logloss:0.06700\n",
      "[349]\tvalidation_0-logloss:0.00262\tvalidation_1-logloss:0.06699\n",
      "[350]\tvalidation_0-logloss:0.00262\tvalidation_1-logloss:0.06697\n",
      "[351]\tvalidation_0-logloss:0.00261\tvalidation_1-logloss:0.06698\n",
      "[352]\tvalidation_0-logloss:0.00260\tvalidation_1-logloss:0.06702\n",
      "[353]\tvalidation_0-logloss:0.00260\tvalidation_1-logloss:0.06716\n",
      "[354]\tvalidation_0-logloss:0.00259\tvalidation_1-logloss:0.06721\n",
      "[355]\tvalidation_0-logloss:0.00259\tvalidation_1-logloss:0.06724\n",
      "[356]\tvalidation_0-logloss:0.00258\tvalidation_1-logloss:0.06713\n",
      "[357]\tvalidation_0-logloss:0.00257\tvalidation_1-logloss:0.06703\n",
      "[358]\tvalidation_0-logloss:0.00257\tvalidation_1-logloss:0.06695\n",
      "[359]\tvalidation_0-logloss:0.00256\tvalidation_1-logloss:0.06696\n",
      "[360]\tvalidation_0-logloss:0.00256\tvalidation_1-logloss:0.06704\n",
      "[361]\tvalidation_0-logloss:0.00255\tvalidation_1-logloss:0.06696\n",
      "[362]\tvalidation_0-logloss:0.00254\tvalidation_1-logloss:0.06691\n",
      "[363]\tvalidation_0-logloss:0.00253\tvalidation_1-logloss:0.06691\n",
      "[364]\tvalidation_0-logloss:0.00253\tvalidation_1-logloss:0.06679\n",
      "[365]\tvalidation_0-logloss:0.00252\tvalidation_1-logloss:0.06669\n",
      "[366]\tvalidation_0-logloss:0.00251\tvalidation_1-logloss:0.06662\n",
      "[367]\tvalidation_0-logloss:0.00251\tvalidation_1-logloss:0.06672\n",
      "[368]\tvalidation_0-logloss:0.00250\tvalidation_1-logloss:0.06684\n",
      "[369]\tvalidation_0-logloss:0.00250\tvalidation_1-logloss:0.06688\n",
      "[370]\tvalidation_0-logloss:0.00250\tvalidation_1-logloss:0.06686\n",
      "[371]\tvalidation_0-logloss:0.00249\tvalidation_1-logloss:0.06680\n",
      "[372]\tvalidation_0-logloss:0.00248\tvalidation_1-logloss:0.06680\n",
      "[373]\tvalidation_0-logloss:0.00248\tvalidation_1-logloss:0.06669\n",
      "[374]\tvalidation_0-logloss:0.00247\tvalidation_1-logloss:0.06647\n",
      "[375]\tvalidation_0-logloss:0.00247\tvalidation_1-logloss:0.06655\n",
      "[376]\tvalidation_0-logloss:0.00246\tvalidation_1-logloss:0.06674\n",
      "[377]\tvalidation_0-logloss:0.00246\tvalidation_1-logloss:0.06675\n",
      "[378]\tvalidation_0-logloss:0.00245\tvalidation_1-logloss:0.06664\n",
      "[379]\tvalidation_0-logloss:0.00244\tvalidation_1-logloss:0.06662\n",
      "[380]\tvalidation_0-logloss:0.00244\tvalidation_1-logloss:0.06669\n",
      "[381]\tvalidation_0-logloss:0.00243\tvalidation_1-logloss:0.06665\n",
      "[382]\tvalidation_0-logloss:0.00243\tvalidation_1-logloss:0.06655\n",
      "[383]\tvalidation_0-logloss:0.00242\tvalidation_1-logloss:0.06641\n",
      "[384]\tvalidation_0-logloss:0.00241\tvalidation_1-logloss:0.06634\n",
      "[385]\tvalidation_0-logloss:0.00241\tvalidation_1-logloss:0.06631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[386]\tvalidation_0-logloss:0.00240\tvalidation_1-logloss:0.06627\n",
      "[387]\tvalidation_0-logloss:0.00239\tvalidation_1-logloss:0.06625\n",
      "[388]\tvalidation_0-logloss:0.00239\tvalidation_1-logloss:0.06627\n",
      "[389]\tvalidation_0-logloss:0.00239\tvalidation_1-logloss:0.06634\n",
      "[390]\tvalidation_0-logloss:0.00238\tvalidation_1-logloss:0.06637\n",
      "[391]\tvalidation_0-logloss:0.00238\tvalidation_1-logloss:0.06647\n",
      "[392]\tvalidation_0-logloss:0.00237\tvalidation_1-logloss:0.06643\n",
      "[393]\tvalidation_0-logloss:0.00237\tvalidation_1-logloss:0.06646\n",
      "[394]\tvalidation_0-logloss:0.00236\tvalidation_1-logloss:0.06644\n",
      "[395]\tvalidation_0-logloss:0.00236\tvalidation_1-logloss:0.06654\n",
      "[396]\tvalidation_0-logloss:0.00236\tvalidation_1-logloss:0.06640\n",
      "[397]\tvalidation_0-logloss:0.00235\tvalidation_1-logloss:0.06645\n",
      "[398]\tvalidation_0-logloss:0.00235\tvalidation_1-logloss:0.06651\n",
      "[399]\tvalidation_0-logloss:0.00234\tvalidation_1-logloss:0.06653\n",
      "오차 행렬\n",
      "[[985  10]\n",
      " [ 30 975]]\n",
      "정확도: 0.9800, 정밀도: 0.9898, 재현율: 0.9701,    F1: 0.9799, AUC:0.9981\n"
     ]
    }
   ],
   "source": [
    "# Q4. fmin()으로 추출된 최적 하이퍼 파라미터를 직접 XGBClassifier에 인자로 입력하기 전에 \n",
    "# 정수형 하이퍼 파라미터(max_depth와 min_child_weight)는 정수형으로 형 변환하고\n",
    "# 실수형 하이퍼 파라미터(colsample_bytree, learning_rate)는 소수점 5자리까지만 변환 하세요.    \n",
    "xgb_wrapper = XGBClassifier(n_estimators=400,\n",
    "                            learning_rate=round(best['learning_rate'],5),\n",
    "                            max_depth=int(best['max_depth']),\n",
    "                            min_child_weight=int(best['min_child_weight']),\n",
    "                            colsample_bytree=round(best['colsample_bytree'],5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 강수민"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression # 메타 모델\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_data = iris.data\n",
    "y_label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Q1. 테스트용 데이터를 20%로 설정해 학습용, 테스트용 데이터를 분할하시오\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data,y_label, test_size=0.2)\n",
    "\n",
    "## 스텝 1 구현\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "RandomForestClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "DecisionTreeClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "AdaBoostClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n"
     ]
    }
   ],
   "source": [
    "# 개별 모델 객체 생성\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "lr_final = LogisticRegression()\n",
    "\n",
    "# Q2. 개별 모델로부터 메타 모델에 필요한 데이터 셋 만들기(n_split=5 로 설정하세요)\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 5)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test,5)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,5)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape: (120, 4) 원본 테스트 피처 Shape: (30, 4)\n",
      "스태킹 학습 피처 데이터 Shape: (120, 4) 스태킹 테스트 피처 데이터 Shape: (30, 4)\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 스텝 2 구현\n",
    "\n",
    "# Q3. 각 모델별 학습 데이터와 테스트 데이터 합치기(칼럼 레벨로 합쳐주기)\n",
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)\n",
    "\n",
    "# Q4. 최종 모델에 학습 시키고, 예측 정확도 확인하기\n",
    "\n",
    "lr_final.fit(X_train,y_train)\n",
    "stack_final = lr_final.predict(X_test)\n",
    "\n",
    "print(accuracy_score(stack_final,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 박민영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               2785 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          2495 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3114 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "water = pd.read_csv('./data/water_potability.csv')\n",
    "water.head(3)\n",
    "\n",
    "# 1. 데이터 정보를 확인하고, 결측치를 평균값으로 대체하세요.\n",
    "water.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               3276 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          3276 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3276 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    }
   ],
   "source": [
    "water.fillna(water.mean(), inplace=True)\n",
    "water.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이상치 데이터 인덱스 : Int64Index([ 142,  186,  283,  287,  366,  378,  405,  516,  546,  613,  666,\n",
      "             987, 1031, 1068, 1077, 1096, 1186, 1302, 1332, 1343, 1445, 1462,\n",
      "            1527, 1554, 1556, 1746, 1784, 1815, 1858, 1955, 1984, 2012, 2497,\n",
      "            2602, 2680, 2758, 2891, 2993, 3014, 3062, 3130, 3150, 3162, 3190,\n",
      "            3226, 3236, 3271],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# 2. 이상치 제거를 위해 정의한 함수입니다. 빈칸을 채워주세요.\n",
    "# Solids 변수에 대해서만 이상치 제거를 할 것입니다.\n",
    "\n",
    "def get_outlier(df = None, column = None, weight = 1.5):\n",
    "    solid = df[column]\n",
    "    quantile_25 = np.percentile(solid, 25)\n",
    "    quantile_75 = np.percentile(solid, 75)\n",
    "    # IQR을 구하고, IQR에 1.5를 곱하여 최대값과 최소값 지점 구함\n",
    "    Iqr = quantile_75 - quantile_25\n",
    "    Iqr_weight = Iqr * weight\n",
    "    lowest_val = quantile_25 - Iqr_weight\n",
    "    highest_val = quantile_75 + Iqr_weight\n",
    "    # 최대값보다 크거나 최소값보다 작은 값을 outlier로 설정하고 DataFrame index 반환\n",
    "    outlier_index = solid[(solid < lowest_val) | (solid > highest_val)].index\n",
    "    return outlier_index\n",
    "\n",
    "# 이상치 인덱스 확인\n",
    "outlier_index = get_outlier(df = water, column = 'Solids', weight = 1.5)\n",
    "print('이상치 데이터 인덱스 :', outlier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. water 데이터프레임에서 이상치를 제거해주세요.\n",
    "water.drop(outlier_index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 아래는 HyperOpt를 통해 최적의 하이퍼 파라미터를 찾으세요.\n",
    "# 빈칸을 알맞게 채워주세요.\n",
    "\n",
    "# 데이터 분리\n",
    "X_features = water.iloc[:, :-1]\n",
    "y_label = water.iloc[:, -1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label,\n",
    "                                                    test_size = 0.1, random_state = 156)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train,\n",
    "                                            test_size = 0.1, random_state = 156)\n",
    "\n",
    "# HyperOpt를 통한 최적 하이퍼 파라미터 추출 - (1) 입력값 설정\n",
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1 간격으로, min_child_weight는 1에서 2까지 1 간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2사이 정규분포된 값으로 검색\n",
    "xgb_search_space = {'max_depth':hp.quniform('max_depth', 5, 20, 1),\n",
    "                    'min_child_weight':hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate':hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree':hp.uniform('colsample_bytree', 0.5, 1)}\n",
    "\n",
    "# HyperOpt를 통한 최적 하이퍼 파라미터 추출 - (2) 목적함수 설정\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함\n",
    "# 정확도는 높을수록 더 좋은 수치임 -> -1을 정확도에 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 n_estimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators = 100, max_depth = int(search_space['max_depth']),\n",
    "                            min_child_weight = int(search_space['min_child_weight']),\n",
    "                            learning_rate = search_space['learning_rate'],\n",
    "                            colsample_bytree = search_space['colsample_bytree'],\n",
    "                            eval_metric = 'logloss')\n",
    "    \n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring = 'accuracy', cv = 3)\n",
    "    \n",
    "    # accuracy는 cv = 3 개수만큼의 정확도 결과를 가지므로 이를 평균해서 반환하되 -1을 곱해줌\n",
    "    return {'loss' : -1 * np.mean(accuracy), 'status' : STATUS_OK}\n",
    "\n",
    "# # HyperOpt를 통한 최적 하이퍼 파라미터 추출 - (3) 최적 하이퍼 파라미터 값 추출\n",
    "\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn = <빈칸>, \n",
    "            space = <빈칸>,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 50, # 최대 반복 횟수를 지정\n",
    "            trials = trial_val, rstate = np.random.default_rng(seed = 9))\n",
    "print('best :', best)\n",
    "\n",
    "print('colsample_bytree : {0}, learning_rate : {1}, max_depth : {2}, min_child_weight : {3}'.format(\n",
    "                        round(best['colsample_bytree'], 5), round(best['learning_rate'], 5),\n",
    "                        int(best['max_depth']), int(best['min_child_weight'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
